---
title: "Recipes"
output: html_document
---

```{r, echo = FALSE, message = FALSE}
source("setup.R")
```

https://recipes.tidymodels.org/

We usually need to manipulate datasets before passing them to a model so that the model can work as effectively as possible. The `recipes` package provides a way to represent pre-processing steps as an object, so that the transformations we do to one dataset can easily be applied to another. 

<br>

### Recipe Initiation ###

Recipe objects are built by creating a "blank" recipe object and then adding on data transformations via functions. 

To initiate a recipe object, we can pass a formula and template dataset to the `recipe()` function. For this example, we are going to start with the `data_split` testing/training split we defined in the [RSample Tutorial](RSample.html).

```{r}
# note that I could also use data_iris, head(data_iris), data_split, etc. as the template; what matters is that the names and types of the variables stay the same. For larger datasets, using head() is preferable.
template_data <- training(data_split)

iris_recipe <- recipe(Species ~ ., 
                      data = template_data)
```

**Note:** If you are building a recipe for a model with a specialized formula (eg. GAMs, which include smoothing functions) do not use it here. The formula should only represent outcomes and predictors, not any special operations/transformations (which can be included later in the `parsnip` model).

Alternatively, we can define a recipe object by passing in a template dataset, a list of all variables to be included in a model, and a list of *roles* corresponding to variables (more on this below!). This is preferable for datasets with a high number of variables. 

```{r}
iris_recipe2 <- recipe (template_data, 
                        vars = c("Sepal.Length", "Sepal.Width", 
                                 "Petal.Length", "Petal.Width", "Species", "row"),
                        roles = c("predictor", "predictor", 
                                 "predictor", "predictor", "outcome", "ID"))
```

<br>

### Roles ###

When we create a recipe, each variable is assigned a *role*, either explicitly by the user or inferred from a formula. A variable can have any role, including outcome, predictor, ID, case weight, stratification variable, etc. The role of a variable determines how it's treated by the model. 

Usually, we only need outcome and predictor roles, which can be assigned automatically via a formula. We can view the roles assigned to variables by a recipe with `summary()`. 

```{r}
iris_recipe |> summary()
# building a recipe that only processes one variable - Sepal.Length - and gives it a "predictor" role
recipe(~ Sepal.Length, data = template_data) |> summary()
# building a recipe with two "outcome" variables
recipe(Species + Sepal.Length ~ ., data = template_data) |> summary()
```

Once we've initiated a recipe, we can change the role for a variable using the `update_role()` function. In the case of `data_iris`, we would want to make `row` an ID variable so that it plays no part in the model but stays attached to the original data for later identification/analysis. 

```{r}
# updating 'row' to an ID variable
iris_recipe <- iris_recipe |>
  # note that we could pass multiple variable names in to change multiple roles at once 
  update_role(row, new_role = "ID") 

summary(iris_recipe)
```

Once roles are assigned to variables, the `recipes` package includes several **selector functions** to easily retrieve variables with specific types and/or roles. These functions are: 

* `has_role()` 
* `has_type()`
* `all_predictors()`
* `all_outcomes()`
* `all_numeric_predictors()`
* `all_nominal_predictors()`
* `all_numeric()`
* `all_nominal()`

Note that factor types are counted as nominal. Also note that some of these functions can only be used within *step functions*. 

<br>

### Step Functions ###

Step functions are used to specify the data transformations that we would like to include in a recipe. Each step function represents a unique data transformation and returns a recipe object with the transformation added. 

Step functions take the following arguments:

* **A recipe object**
* **A selector function** or list of variables to which the step will be applied
* **Optional additional specifiers** 

Some examples of step functions include: 

* `step_corr()` - removes highly correlated variables
* `step_log()` - log transforms data 
* `step_center()` - centers variables to have a mean of 0
* `step_scale()` - scales variables to have a standard deviation of 1 
* `step_zv()` / `step_nzv()` - removes zero / near-zero variance predictors
* `step_naomit()` - removes missing values
* `step_dummy()` - converts nominal variables to *dummy/indicator* variables, which is useful when a model can only process numeric data. Note that some `parsnip` models, such as GAMs, will do this for you automatically. 

There are also several step functions that act as wrappers for common `dplyr` operations:

* `step_select()`
* `step_filter()`
* `step_arrange()`
* `step_sample()`
* `step_slice()`
* `step_rename()` and `step_rename_at()`
* `step_mutate()` and `step_mutate_at()` - note that the new variables created by these operations have their *roles* specified within the functions' arguments. 

```{r}
# adding some steps to our iris_recipe object
iris_recipe <- iris_recipe |>
  step_corr(all_numeric_predictors()) |>
  # step_normalize() applies both step_center() and step_scale()
  step_normalize(all_numeric_predictors()) |>
  # renaming the row variable 
  step_rename(Row = row)

# calling the recipe prints its information - notice the steps listed
iris_recipe
```

Step functions can also cover much more complex operations. For a full list of step functions, see the official [Function Reference](https://recipes.tidymodels.org/reference/index.html).

**Note:** Since step functions are applied successively to a recipe object, order matters. The [Recipes Website](https://recipes.tidymodels.org/articles/Ordering.html) has some tips and tricks for how to handle ordering step functions. 

<br>

### Prepping the Recipe and Baking New Data ###

Once we've added all the desired roles and steps to a recipe, we use the `prep()` function to "train" the recipe on the template data -- that is, we use the template data to estimate the parameters/quantities required by steps. 

```{r}
# preparing the recipe using prep() 
iris_recipe_prepped <- iris_recipe |>
  prep()

# note that the steps are now trained for the template dataset
iris_recipe_prepped
```

Finally, we can use the prepped recipe to process data. Use `juice()` to extract the processed template data from a recipe, and use `bake()` to process new data.  

**Note**: `prep()` **must** be called before using a recipe to bake data - otherwise, the steps are not trained and the code will error.

```{r, error = TRUE}
# attempting to process data before calling prep(), causing an error
bake(iris_recipe, testing(data_split))

# extracting the training data using `juice()` 
prepped_training <- juice(iris_recipe_prepped)
head(prepped_training)

# taking a glimpse at an unprocessed data set
head(testing(data_split))

# processing the dataset using bake()
prepped_testing <- bake(iris_recipe_prepped, testing(data_split))
head(prepped_testing)
```

<br>

### Further Resources ###

* https://www.tidymodels.org/start/recipes/
  * A general walkthrough of the tidymodels process that pays special attention to the creation and application of recipes. 
* https://recipes.tidymodels.org/articles/Roles.html
  * Further detail about roles in recipes 

